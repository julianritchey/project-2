import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Activation

# This code is neccessary to produce the same results every time
import tensorflow as tf
from keras.models import Sequential, Model
from keras.layers import Dense, Activation, Dropout
from sklearn.preprocessing import StandardScaler
import hvplot.pandas
from pathlib import Path
from sklearn.linear_model import LinearRegression

from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from imblearn.metrics import classification_report_imbalanced
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression


from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from sklearn.preprocessing import StandardScaler


from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
#from keras.models import Sequential
#from keras.layers import Dense



risk_tolerance_data = pd.read_csv('us_input_data.csv')
risk_tolerance_data.head()
risk_tolerance_data.columns


risk_tol_assess_model = risk_tolerance_data.rename(columns={
    'Unnamed: 0': 'PROFILE ID',
    'AGE07': 'AGE',
    'EDCL07': 'EDUCATION',
    'MARRIED07': 'MARITAL STATUS',
    'KIDS07': 'CHILDREN',
    'LIFECL07': 'LIFE CYCLE SEGMENT',
    'OCCAT107': 'EMPLOYMENT',
    'INCOME07': 'INCOME',
    'RISK07': 'RISK TENDENCY',
    'WSAVED07': 'SAVING POTENTIAL',
    'SPENDMOR07': 'SPENDING POTENTIAL',
    'NETWORTH07': 'NET WORTH',
    'TrueRiskTol': 'TRUE RISK TOLERANCE'
})
risk_tol_assess_model.columns



# Calculate descriptive statistics
#min_value = np.min(risk_tol_assess_model['TRUE RISK TOLERANCE'])
#max_value = np.max(risk_tol_assess_model['TRUE RISK TOLERANCE'])
#mean_value = np.mean(risk_tol_assess_model['TRUE RISK TOLERANCE'])
#median_value = np.median(risk_tol_assess_model['TRUE RISK TOLERANCE'])
#std_value = np.std(risk_tol_assess_model['TRUE RISK TOLERANCE'])

# Printing the descriptive statistics
#print("Min:", min_value)
#print("Max:", max_value)
#print("Mean:", mean_value)
#print("Median:", median_value)
#print("Standard Deviation:", std_value)


#Determine Threshold Ranges for Categorical Mapping:

percentiles = np.percentile(risk_tol_assess_model['TRUE RISK TOLERANCE'], [25, 75])
low_risk_threshold = percentiles[0]
conservative_threshold = percentiles[1]


# Determine Threshold Ranges for Categorical Mapping:
percentiles = np.percentile(risk_tol_assess_model['TRUE RISK TOLERANCE'], [25, 75])
low_risk_threshold = percentiles[0]
conservative_threshold = percentiles[1]

# Define categorical values based on thresholds
risk_aversion_profile = []
for risk_tolerance in risk_tol_assess_model['TRUE RISK TOLERANCE']:
    if risk_tolerance < low_risk_threshold:
        risk_aversion_profile.append('Low Risk')
    elif risk_tolerance < conservative_threshold:
        risk_aversion_profile.append('Moderate Risk')
    else:
        risk_aversion_profile.append('High Risk')

# Add risk aversion categories to the dataframe
risk_tol_assess_model['RISK PROFILE TYPE'] = risk_aversion_profile


risk_tol_assess_model.head()


# Select the relevant columns as features and target
#feature_columns = ['AGE', 'EDUCATION', 'MARITAL STATUS', 'CHILDREN',
       #'LIFE CYCLE SEGMENT', 'EMPLOYMENT', 'INCOME', 'RISK TENDENCY',
       #'SAVING POTENTIAL', 'SPENDING POTENTIAL', 'NET WORTH',
       #'TRUE RISK TOLERANCE']

#target_column = ['RISK PROFILE TYPE']


#X = risk_tol_assess_model[feature_columns]
#y = risk_tol_assess_model[target_column]


#Select the relevant columns as features and target
feature_columns = ['AGE', 'EDUCATION', 'CHILDREN', 'INCOME','NET WORTH','TRUE RISK TOLERANCE']
target_column = ['RISK PROFILE TYPE']

X = risk_tol_assess_model[feature_columns]
y = risk_tol_assess_model[target_column]


y.value_counts()


# Create a dictionary to map the class names to numerical labels
label_mapping = {
    'Low Risk': 1,
    'Moderate Risk': 2,
    'High Risk': 3
}

# Map the labels using the dictionary
y_encoded = y['RISK PROFILE TYPE'].map(label_mapping)

# Print the encoded labels
print(y_encoded)


unique_labels = np.unique(y_encoded)
print(unique_labels)


# Print unique values in y_encoded
print(np.unique(y_encoded))


#FIRST MODEL RANDOM FORREST

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, random_state=1)

scaler = StandardScaler()
X_scaler = scaler.fit(X_train)


# Scale the training data
X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)


# Create the random forest classifier instance
from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(random_state=1)
rf_model = rf_model.fit(X_train_scaled, y_train)


#Making Predictions
y_pred = rf_model.predict(X_test_scaled)


from sklearn.metrics import accuracy_score, classification_report

accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print('Accuracy:', accuracy)
print('Classification Report:')
print(report)


from sklearn.metrics import confusion_matrix

# Calculating the confusion matrix
cm = confusion_matrix(y_test, y_pred)
cm_df = pd.DataFrame(
    cm, index=['Actual 1', 'Actual 2', 'Actual 3' ], columns=['Predicted 1', 'Predicted 2', 'Predicted 3']
)

print('Confusion Matrix - Original data')
display(cm_df)


# Get the feature importance array
importances = rf_model.feature_importances_
# List the top 10 most important features
importances_sorted = sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)
importances_sorted[:6]


import itertools

# Plotting the confusion matrix
plt.imshow(cm, cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
classes = ['Low Risk', 'Moderate Risk', 'High Risk']
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes)
plt.yticks(tick_marks, classes)
plt.xlabel('Predicted Labels of Random Forrest Model')
plt.ylabel('True Labels of Random Forrest Model')

# Adding labels to each cell
thresh = cm.max() / 2
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j, i, cm[i, j],
             horizontalalignment='center',
             color='white' if cm[i, j] > thresh else 'black')

plt.show()


#Random Undersampler

# Import RandomUnderSampler from imblearn
from imblearn.under_sampling import RandomUnderSampler

# Instantiate a RandomUnderSampler instance
rus = RandomUnderSampler(random_state=1)

# Fit the training data to the random undersampler model
X_undersampled, y_undersampled = rus.fit_resample(X_train_scaled, y_train)


# Count distinct values for the resampled target data
y_undersampled.value_counts()


# Instantiate a new RandomForestClassier model
rf_undersampled = RandomForestClassifier()

# Fit the undersampled data the new model
rf_undersampled.fit(X_undersampled, y_undersampled)


# Predict labels for oversampled testing features
y_pred_undersampled = rf_undersampled.predict(X_test_scaled)


# Print classification reports

print('Classifiction Report - Undersampled Data')
print(classification_report(y_test, y_pred_undersampled))


# Calculating the confusion matrix
cm_undersampled = confusion_matrix(y_test, y_pred_undersampled)
cm_undersampled_df = pd.DataFrame(
    cm_undersampled, index=['Actual 1', 'Actual 2', 'Actual 3' ], columns=['Predicted 1', 'Predicted 2', 'Predicted 3']
)

print('Confusion Matrix - Undersampled Data')
display(cm_undersampled_df)


# Get the feature importance array
importances = rf_undersampled.feature_importances_
# List the top 10 most important features
importances_sorted = sorted(zip(rf_undersampled.feature_importances_, X.columns), reverse=True)
importances_sorted[:6]


#Random Oversampler

# Import RandomOverSampler from imblearn
from imblearn.over_sampling import RandomOverSampler

# Instantiate a RandomOversampler instance
ros = RandomOverSampler(random_state=1)

# Fit the model to the training data
X_oversampled, y_oversampled = ros.fit_resample(X_train_scaled, y_train)


# Count distinct values
y_oversampled.value_counts()


# Instantiate a new RandomForestClassier model
rf_oversampled = RandomForestClassifier()

# Fit the oversampled data the new model
rf_oversampled.fit(X_oversampled, y_oversampled)


# Predict labels for oversampled testing features
y_pred_oversampled = rf_oversampled.predict(X_test_scaled)


# Print classification reports

print('Classifiction Report - Oversampled Data')
print(classification_report(y_test, y_pred_oversampled))


cm_oversampled = confusion_matrix(y_test, y_pred_oversampled)
cm_oversampled_df = pd.DataFrame(
    cm_oversampled, index=['Actual 1', 'Actual 2', 'Actual 3' ], columns=['Predicted 1', 'Predicted 2', 'Predicted 3']
)

print('Confusion Matrix - Oversampled data' )
display(cm_oversampled_df)


# Get the feature importance array
importances = rf_oversampled.feature_importances_
# List the top 10 most important features
importances_sorted = sorted(zip(rf_oversampled.feature_importances_, X.columns), reverse=True)
importances_sorted[:6]


#Cluster Centroids

# Import ClusterCentroids from imblearn
from imblearn.under_sampling import ClusterCentroids

# Instantiate a ClusterCentroids instance
cc_sampler = ClusterCentroids(random_state=1)


# Fit the training data to the cluster centroids model
X_resampled, y_resampled = cc_sampler.fit_resample(X_train_scaled, y_train)


y_resampled.value_counts()


# Instantiate a new RandomForestClassier model
cc_model = RandomForestClassifier()

# Fit the resampled data the new model
cc_model.fit(X_resampled, y_resampled)


# Predict labels for resampled testing features
cc_y_pred = cc_model.predict(X_test_scaled)


print('Classifiction Report - Redsampled Data - CentroidClusters')
print(classification_report(y_test, cc_y_pred))


#SMOTE

# Import SMOTE from imblearn
from imblearn.over_sampling import SMOTE

# Instantiate the SMOTE instance 
# Set the sampling_strategy parameter equal to auto
smote_sampler = SMOTE(random_state=1, sampling_strategy='auto')

#SMOTE is an oversampling technique that generates synthetic samples for the minority class by
#interpolating between existing instances of that class. 


# Fit the training data to the smote_sampler model
X_resampled, y_resampled = smote_sampler.fit_resample(X_train_scaled, y_train)


# Count distinct values for the resampled target data
y_resampled.value_counts()


# Instantiate a new RandomForestClassier model 
smote_model = RandomForestClassifier()

# Fit the resampled data to the new model
smote_model.fit(X_resampled, y_resampled)


# Predict labels for resampled testing features
smote_y_pred = smote_model.predict(X_test_scaled)


print('Classifiction Report - Resampled Data - SMOTE')
print(classification_report(y_test, smote_y_pred))


#Import SMOTEEN from imblearn
from imblearn.combine import SMOTEENN

# Instantiate the SMOTEENN instance
smote_enn = SMOTEENN(random_state=1)

#SMOTE-ENN combines the SMOTE oversampling technique with the Edited Nearest Neighbors (ENN) undersampling technique


# Fit the model to the training data
X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled, y_train)


# Count distinct values for the resampled target data
y_resampled.value_counts()


# Instantiate a new RandomForestClassier model
smoteenn_model = RandomForestClassifier()

# Fit the resampled data the new model
smoteenn_model.fit(X_resampled, y_resampled)


# Predict labels for resampled testing features
smoteenn_y_pred = smoteenn_model.predict(X_test_scaled)


print('Classifiction Report - Redsampled Data - SMOTEENN')
print(classification_report(y_test, smoteenn_y_pred))



