import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Activation

# This code is neccessary to produce the same results every time
import tensorflow as tf
from keras.models import Sequential, Model
from keras.layers import Dense, Activation, Dropout
from sklearn.preprocessing import StandardScaler
import hvplot.pandas
from pathlib import Path
from sklearn.linear_model import LinearRegression

from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from imblearn.metrics import classification_report_imbalanced
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression


from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from sklearn.preprocessing import StandardScaler


from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
#from keras.models import Sequential
#from keras.layers import Dense



risk_tolerance_data = pd.read_csv('us_input_data.csv')
risk_tolerance_data.head()
risk_tolerance_data.columns


risk_tol_assess_model = risk_tolerance_data.rename(columns={
    'Unnamed: 0': 'PROFILE ID',
    'AGE07': 'AGE',
    'EDCL07': 'EDUCATION',
    'MARRIED07': 'MARITAL STATUS',
    'KIDS07': 'CHILDREN',
    'LIFECL07': 'LIFE CYCLE SEGMENT',
    'OCCAT107': 'EMPLOYMENT',
    'INCOME07': 'INCOME',
    'RISK07': 'RISK TENDENCY',
    'WSAVED07': 'SAVING POTENTIAL',
    'SPENDMOR07': 'SPENDING POTENTIAL',
    'NETWORTH07': 'NET WORTH',
    'TrueRiskTol': 'TRUE RISK TOLERANCE'
})
risk_tol_assess_model


# Determine the risk profile score thresholds using percentiles
percentiles = np.percentile(risk_tol_assess_model['TRUE RISK TOLERANCE'], [25, 75])
low_risk_threshold = percentiles[0]
conservative_threshold = percentiles[1]

# Define the risk profile score categories and their numerical scores
risk_profile_scores = {
    'Low risk averse': 1,
    'Moderate risk averse': 2,
    'High risk averse': 3
}



# Create a new column 'RISK PROFILE SCORE' and assign initial values
risk_tol_assess_model['RISK PROFILE SCORE'] = 0

# Categorize the risk profile scores and assign numerical scores
risk_tol_assess_model.loc[risk_tol_assess_model['TRUE RISK TOLERANCE'] <= low_risk_threshold, 'RISK PROFILE SCORE'] = risk_profile_scores['Low risk averse']
risk_tol_assess_model.loc[(risk_tol_assess_model['TRUE RISK TOLERANCE'] > low_risk_threshold) & (risk_tol_assess_model['TRUE RISK TOLERANCE'] <= conservative_threshold), 'RISK PROFILE SCORE'] = risk_profile_scores['Moderate risk averse']
risk_tol_assess_model.loc[risk_tol_assess_model['TRUE RISK TOLERANCE'] > conservative_threshold, 'RISK PROFILE SCORE'] = risk_profile_scores['High risk averse']



risk_tol_assess_model.head(50)


print(risk_tol_assess_model['RISK PROFILE SCORE'].unique())



sample_data = risk_tol_assess_model[['TRUE RISK TOLERANCE', 'RISK PROFILE SCORE']].sample(5)
print(sample_data)



score_counts = risk_tol_assess_model['RISK PROFILE SCORE'].value_counts()
print(score_counts)






import matplotlib.pyplot as plt

# Count the occurrences of each risk profile score
score_counts = risk_tol_assess_model['RISK PROFILE SCORE'].value_counts()

# Create a bar plot
plt.bar(score_counts.index, score_counts.values)

# Add labels and title
plt.xlabel('Risk Profile Score')
plt.ylabel('Count')
plt.title('Distribution of Risk Profile Scores')

# Set x-axis tick labels
plt.xticks(score_counts.index)

# Show the plot
plt.show()



low_risk_rows = risk_tol_assess_model[risk_tol_assess_model['RISK PROFILE SCORE'] == 1]
print(low_risk_rows)



moderate_risk_rows = risk_tol_assess_model[risk_tol_assess_model['RISK PROFILE SCORE'] == 2]
print(moderate_risk_rows)



high_risk_rows = risk_tol_assess_model[risk_tol_assess_model['RISK PROFILE SCORE'] == 3]
print(high_risk_rows)



percentiles = np.percentile(risk_tol_assess_model['TRUE RISK TOLERANCE'], [25, 75])
low_risk_threshold = percentiles[0]
conservative_threshold = percentiles[1]



risk_tol_assess_model.loc[risk_tol_assess_model['TRUE RISK TOLERANCE'] <= low_risk_threshold, 'RISK PROFILE SCORE'] = risk_profile_scores['Low risk averse']
risk_tol_assess_model.loc[(risk_tol_assess_model['TRUE RISK TOLERANCE'] > low_risk_threshold) & (risk_tol_assess_model['TRUE RISK TOLERANCE'] <= conservative_threshold), 'RISK PROFILE SCORE'] = risk_profile_scores['Moderate risk averse']
risk_tol_assess_model.loc[risk_tol_assess_model['TRUE RISK TOLERANCE'] > conservative_threshold, 'RISK PROFILE SCORE'] = risk_profile_scores['High risk averse']



score_counts = risk_tol_assess_model['RISK PROFILE SCORE'].value_counts()
print(score_counts)



print(risk_tol_assess_model['TRUE RISK TOLERANCE'].describe())



import matplotlib.pyplot as plt

plt.hist(risk_tol_assess_model['TRUE RISK TOLERANCE'], bins=20)
plt.xlabel('TRUE RISK TOLERANCE')
plt.ylabel('Frequency')
plt.title('Distribution of TRUE RISK TOLERANCE')
plt.show()



sample_data = risk_tol_assess_model.sample(n=50)  # Change n to the desired number of data points to inspect

for index, row in sample_data.iterrows():
    true_risk_tolerance = row['TRUE RISK TOLERANCE']
    risk_profile_score = row['RISK PROFILE SCORE']
    print(f'True Risk Tolerance: {true_risk_tolerance:.2f} | Risk Profile Score: {risk_profile_score}')



low_risk_data = risk_tol_assess_model[risk_tol_assess_model['RISK PROFILE SCORE'] == 1]
moderate_risk_data = risk_tol_assess_model[risk_tol_assess_model['RISK PROFILE SCORE'] == 2]
high_risk_data = risk_tol_assess_model[risk_tol_assess_model['RISK PROFILE SCORE'] == 3]



low_risk_data.head(10)


high_risk_data.head(10)


#Determine Threshold Ranges for Categorical Mapping:

percentiles = np.percentile(risk_tol_assess_model['TRUE RISK TOLERANCE'], [25, 75])
low_risk_threshold = percentiles[0]
conservative_threshold = percentiles[1]


moderate_risk_data.head(10)


# Example: Analyzing age distribution
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.hist(low_risk_data['AGE'], bins=10, color='blue', alpha=0.5, label='Low Risk')
plt.hist(moderate_risk_data['AGE'], bins=10, color='orange', alpha=0.5, label='Moderate Risk')
plt.hist(high_risk_data['AGE'], bins=10, color='green', alpha=0.5, label='High Risk')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Distribution of Age for Risk Profile Scores')
plt.legend()
plt.show()



# Visualize income and age
plt.figure(figsize=(10, 6))
plt.scatter(risk_tol_assess_model['AGE'], risk_tol_assess_model['INCOME'], color='blue')
plt.xlabel('Age')
plt.ylabel('Income')
plt.title('Income vs. Age')
plt.show()


# Visualize income and age using bar plot
plt.figure(figsize=(10, 6))
plt.bar(risk_tol_assess_model['AGE'], risk_tol_assess_model['INCOME'], color='blue')
plt.xlabel('Age')
plt.ylabel('Income')
plt.title('Income Distribution by Age')
plt.show()



# Visualize net worth and age
plt.figure(figsize=(10, 6))
plt.scatter(risk_tol_assess_model['AGE'], risk_tol_assess_model['NET WORTH'], color='purple')
plt.xlabel('Age')
plt.ylabel('Net Worth')
plt.title('Net Worth vs. Age')
plt.show()


# Visualize net worth and age using bar plot
plt.figure(figsize=(10, 6))
plt.bar(risk_tol_assess_model['AGE'], risk_tol_assess_model['NET WORTH'], color='purple')
plt.xlabel('Age')
plt.ylabel('Net Worth')
plt.title('Net Worth Distribution by Age')
plt.show()


# Visualize education and age
plt.figure(figsize=(10, 6))
plt.scatter(risk_tol_assess_model['AGE'], risk_tol_assess_model['EDUCATION'], color='green')
plt.xlabel('Age')
plt.ylabel('Education')
plt.title('Education vs. Age')
plt.show()


import matplotlib.pyplot as plt

# Create subplots for each variable
fig, axs = plt.subplots(2, 2, figsize=(12, 8))
fig.suptitle('Distribution of Variables by Risk Profile')

# Plot for Age
axs[0, 0].hist(low_risk_data['AGE'], bins=10, alpha=0.5, label='Low Risk')
axs[0, 0].hist(moderate_risk_data['AGE'], bins=10, alpha=0.5, label='Moderate Risk')
axs[0, 0].hist(high_risk_data['AGE'], bins=10, alpha=0.5, label='High Risk')
axs[0, 0].set_xlabel('Age')
axs[0, 0].set_ylabel('Frequency')
axs[0, 0].legend()

# Plot for Income
axs[0, 1].hist(low_risk_data['INCOME'], bins=10, alpha=0.5, label='Low Risk')
axs[0, 1].hist(moderate_risk_data['INCOME'], bins=10, alpha=0.5, label='Moderate Risk')
axs[0, 1].hist(high_risk_data['INCOME'], bins=10, alpha=0.5, label='High Risk')
axs[0, 1].set_xlabel('Income')
axs[0, 1].set_ylabel('Frequency')
axs[0, 1].legend()

# Plot for Education
axs[1, 0].hist(low_risk_data['EDUCATION'], bins=10, alpha=0.5, label='Low Risk')
axs[1, 0].hist(moderate_risk_data['EDUCATION'], bins=10, alpha=0.5, label='Moderate Risk')
axs[1, 0].hist(high_risk_data['EDUCATION'], bins=10, alpha=0.5, label='High Risk')
axs[1, 0].set_xlabel('Education')
axs[1, 0].set_ylabel('Frequency')
axs[1, 0].legend()

# Plot for Net Worth
axs[1, 1].hist(low_risk_data['NET WORTH'], bins=10, alpha=0.5, label='Low Risk')
axs[1, 1].hist(moderate_risk_data['NET WORTH'], bins=10, alpha=0.5, label='Moderate Risk')
axs[1, 1].hist(high_risk_data['NET WORTH'], bins=10, alpha=0.5, label='High Risk')
axs[1, 1].set_xlabel('Net Worth')
axs[1, 1].set_ylabel('Frequency')
axs[1, 1].legend()

plt.tight_layout()
plt.show()















# Determine Threshold Ranges for Categorical Mapping:
percentiles = np.percentile(risk_tol_assess_model['TRUE RISK TOLERANCE'], [25, 75])
low_risk_threshold = percentiles[0]
conservative_threshold = percentiles[1]

# Define categorical values based on thresholds
risk_aversion_profile = []
for risk_tolerance in risk_tol_assess_model['TRUE RISK TOLERANCE']:
    if risk_tolerance < low_risk_threshold:
        risk_aversion_profile.append('Low Risk')
    elif risk_tolerance < conservative_threshold:
        risk_aversion_profile.append('Moderate Risk')
    else:
        risk_aversion_profile.append('High Risk')

# Add risk aversion categories to the dataframe
risk_tol_assess_model['RISK PROFILE TYPE'] = risk_aversion_profile


risk_tol_assess_model['RISK PROFILE TYPE'] = risk_tol_assess_model['RISK PROFILE TYPE'].map({'Low Risk': 1, 'Moderate Risk': 2, 'High Risk': 3})



print(risk_tol_assess_model['RISK PROFILE TYPE'].unique())



risk_tol_assess_model.head()


# Select the relevant columns as features and target
#feature_columns = ['AGE', 'EDUCATION', 'MARITAL STATUS', 'CHILDREN',
       #'LIFE CYCLE SEGMENT', 'EMPLOYMENT', 'INCOME', 'RISK TENDENCY',
       #'SAVING POTENTIAL', 'SPENDING POTENTIAL', 'NET WORTH',
       #'TRUE RISK TOLERANCE']

#target_column = ['RISK PROFILE TYPE']


#X = risk_tol_assess_model[feature_columns]
#y = risk_tol_assess_model[target_column]


#Select the relevant columns as features and target
feature_columns = ['AGE', 'EDUCATION', 'CHILDREN', 'INCOME','NET WORTH','TRUE RISK TOLERANCE']
target_column = ['RISK PROFILE TYPE']

X = risk_tol_assess_model[feature_columns]
y = risk_tol_assess_model[target_column]


y.value_counts()


# Create a dictionary to map the class names to numerical labels
label_mapping = {
    'Low Risk': 1,
    'Moderate Risk': 2,
    'High Risk': 3
}

# Map the labels using the dictionary
y_encoded = y['RISK PROFILE TYPE'].map(label_mapping)

# Print the encoded labels
print(y_encoded)


unique_labels = np.unique(y_encoded)
print(unique_labels)


# Print unique values in y_encoded
print(np.unique(y_encoded))


#FIRST MODEL RANDOM FORREST

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, random_state=1)

scaler = StandardScaler()
X_scaler = scaler.fit(X_train)


# Scale the training data
X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)


# Create the random forest classifier instance
from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(random_state=1)
rf_model = rf_model.fit(X_train_scaled, y_train)


#Making Predictions
y_pred = rf_model.predict(X_test_scaled)


from sklearn.metrics import accuracy_score, classification_report

accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print('Accuracy:', accuracy)
print('Classification Report:')
print(report)


from sklearn.metrics import confusion_matrix

# Calculating the confusion matrix
cm = confusion_matrix(y_test, y_pred)
cm_df = pd.DataFrame(
    cm, index=['Actual 1', 'Actual 2', 'Actual 3' ], columns=['Predicted 1', 'Predicted 2', 'Predicted 3']
)

print('Confusion Matrix - Original data')
display(cm_df)


# Get the feature importance array
importances = rf_model.feature_importances_
# List the top 10 most important features
importances_sorted = sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)
importances_sorted[:6]


import itertools

# Plotting the confusion matrix
plt.imshow(cm, cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
classes = ['Low Risk', 'Moderate Risk', 'High Risk']
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes)
plt.yticks(tick_marks, classes)
plt.xlabel('Predicted Labels of Random Forrest Model')
plt.ylabel('True Labels of Random Forrest Model')

# Adding labels to each cell
thresh = cm.max() / 2
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j, i, cm[i, j],
             horizontalalignment='center',
             color='white' if cm[i, j] > thresh else 'black')

plt.show()


#Random Undersampler

# Import RandomUnderSampler from imblearn
from imblearn.under_sampling import RandomUnderSampler

# Instantiate a RandomUnderSampler instance
rus = RandomUnderSampler(random_state=1)

# Fit the training data to the random undersampler model
X_undersampled, y_undersampled = rus.fit_resample(X_train_scaled, y_train)


# Count distinct values for the resampled target data
y_undersampled.value_counts()


# Instantiate a new RandomForestClassier model
rf_undersampled = RandomForestClassifier()

# Fit the undersampled data the new model
rf_undersampled.fit(X_undersampled, y_undersampled)


# Predict labels for oversampled testing features
y_pred_undersampled = rf_undersampled.predict(X_test_scaled)


# Print classification reports

print('Classifiction Report - Undersampled Data')
print(classification_report(y_test, y_pred_undersampled))


# Calculating the confusion matrix
cm_undersampled = confusion_matrix(y_test, y_pred_undersampled)
cm_undersampled_df = pd.DataFrame(
    cm_undersampled, index=['Actual 1', 'Actual 2', 'Actual 3' ], columns=['Predicted 1', 'Predicted 2', 'Predicted 3']
)

print('Confusion Matrix - Undersampled Data')
display(cm_undersampled_df)


# Get the feature importance array
importances = rf_undersampled.feature_importances_
# List the top 10 most important features
importances_sorted = sorted(zip(rf_undersampled.feature_importances_, X.columns), reverse=True)
importances_sorted[:6]


#Random Oversampler

# Import RandomOverSampler from imblearn
from imblearn.over_sampling import RandomOverSampler

# Instantiate a RandomOversampler instance
ros = RandomOverSampler(random_state=1)

# Fit the model to the training data
X_oversampled, y_oversampled = ros.fit_resample(X_train_scaled, y_train)


# Count distinct values
y_oversampled.value_counts()


# Instantiate a new RandomForestClassier model
rf_oversampled = RandomForestClassifier()

# Fit the oversampled data the new model
rf_oversampled.fit(X_oversampled, y_oversampled)


# Predict labels for oversampled testing features
y_pred_oversampled = rf_oversampled.predict(X_test_scaled)


# Print classification reports

print('Classifiction Report - Oversampled Data')
print(classification_report(y_test, y_pred_oversampled))


cm_oversampled = confusion_matrix(y_test, y_pred_oversampled)
cm_oversampled_df = pd.DataFrame(
    cm_oversampled, index=['Actual 1', 'Actual 2', 'Actual 3' ], columns=['Predicted 1', 'Predicted 2', 'Predicted 3']
)

print('Confusion Matrix - Oversampled data' )
display(cm_oversampled_df)


# Get the feature importance array
importances = rf_oversampled.feature_importances_
# List the top 10 most important features
importances_sorted = sorted(zip(rf_oversampled.feature_importances_, X.columns), reverse=True)
importances_sorted[:6]


#Cluster Centroids

# Import ClusterCentroids from imblearn
from imblearn.under_sampling import ClusterCentroids

# Instantiate a ClusterCentroids instance
cc_sampler = ClusterCentroids(random_state=1)


# Fit the training data to the cluster centroids model
X_resampled, y_resampled = cc_sampler.fit_resample(X_train_scaled, y_train)


y_resampled.value_counts()


# Instantiate a new RandomForestClassier model
cc_model = RandomForestClassifier()

# Fit the resampled data the new model
cc_model.fit(X_resampled, y_resampled)


# Predict labels for resampled testing features
cc_y_pred = cc_model.predict(X_test_scaled)


print('Classifiction Report - Redsampled Data - CentroidClusters')
print(classification_report(y_test, cc_y_pred))


#SMOTE

# Import SMOTE from imblearn
from imblearn.over_sampling import SMOTE

# Instantiate the SMOTE instance 
# Set the sampling_strategy parameter equal to auto
smote_sampler = SMOTE(random_state=1, sampling_strategy='auto')

#SMOTE is an oversampling technique that generates synthetic samples for the minority class by
#interpolating between existing instances of that class. 


# Fit the training data to the smote_sampler model
X_resampled, y_resampled = smote_sampler.fit_resample(X_train_scaled, y_train)


# Count distinct values for the resampled target data
y_resampled.value_counts()


# Instantiate a new RandomForestClassier model 
smote_model = RandomForestClassifier()

# Fit the resampled data to the new model
smote_model.fit(X_resampled, y_resampled)


# Predict labels for resampled testing features
smote_y_pred = smote_model.predict(X_test_scaled)


print('Classifiction Report - Resampled Data - SMOTE')
print(classification_report(y_test, smote_y_pred))


#Import SMOTEEN from imblearn
from imblearn.combine import SMOTEENN

# Instantiate the SMOTEENN instance
smote_enn = SMOTEENN(random_state=1)

#SMOTE-ENN combines the SMOTE oversampling technique with the Edited Nearest Neighbors (ENN) undersampling technique


# Fit the model to the training data
X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled, y_train)


# Count distinct values for the resampled target data
y_resampled.value_counts()


# Instantiate a new RandomForestClassier model
smoteenn_model = RandomForestClassifier()

# Fit the resampled data the new model
smoteenn_model.fit(X_resampled, y_resampled)


# Predict labels for resampled testing features
smoteenn_y_pred = smoteenn_model.predict(X_test_scaled)


print('Classifiction Report - Redsampled Data - SMOTEENN')
print(classification_report(y_test, smoteenn_y_pred))



