import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import hvplot.pandas
from pathlib import Path

# This code is neccessary to produce the same results every time
import tensorflow as tf
from keras.models import Sequential, Model
from keras.layers import Dense, Activation, Dropout
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split
from imblearn.metrics import classification_report_imbalanced
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from keras.metrics import categorical_accuracy


risk_tolerance_data = pd.read_csv('us_input_data.csv')
risk_tolerance_data.head()
risk_tolerance_data.columns


risk_tol_model = risk_tolerance_data.rename(columns={
    'Unnamed: 0': 'PROFILE ID',
    'AGE07': 'AGE',
    'EDCL07': 'EDUCATION',
    'MARRIED07': 'MARRIAGE',
    'LIFECL07': 'QUALITY OF LIFE',
    'KIDS07': 'KIDS',
    'OCCAT107': 'EMPLOYMENT',
    'INCOME07': 'INCOME',
    'RISK07': 'RISK TENDENCY',
    'WSAVED07': 'SAVING POTENTIAL',
    'SPENDMOR07': 'SPENDING POTENTIAL',
    'NETWORTH07': 'NET WORTH',
    'TrueRiskTol': 'TRUE RISK TOLERANCE'
})
risk_tol_model.dropna()
risk_tol_model.columns
risk_tol_model.tail()


import seaborn as sns
# Calculate the correlation matrix
correlation_matrix = risk_tol_model.corr()

# Plot the correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()


# Calculate the correlation between features and target variable
target_correlations = correlation_matrix['TRUE RISK TOLERANCE'].abs().sort_values(ascending=False)

# Print the correlations
print(target_correlations)


# Select the top N features with the strongest correlation
num_features = 10 # Number of features to select
strongest_corr_features = target_correlations[1:num_features + 1].index
# Print the names of the selected features
print(strongest_corr_features)


print(risk_tol_model['TRUE RISK TOLERANCE'].dtype)


print(risk_tol_model['TRUE RISK TOLERANCE'].isnull().sum())


columns_to_keep = ['AGE', 'KIDS', 'NET WORTH' , 'INCOME', 'MARRIAGE', 'TRUE RISK TOLERANCE']
risk_tol_model = risk_tol_model[columns_to_keep]


print(risk_tol_model['TRUE RISK TOLERANCE'].describe())


# Plot a histogram to visualize the distribution
plt.hist(risk_tol_model['TRUE RISK TOLERANCE'], bins=20)
plt.xlabel('TRUE RISK TOLERANCE')
plt.ylabel('Frequency')
plt.title('Distribution of TRUE RISK TOLERANCE')
plt.show()

# Calculate the value counts for each level
value_counts = risk_tol_model['TRUE RISK TOLERANCE'].value_counts().sort_index()


# Set the number of bins based on the data range and granularity desired
num_bins = 50

# Plot a histogram to visualize the distribution
plt.hist(risk_tol_model['TRUE RISK TOLERANCE'], bins=num_bins)
plt.xlabel('TRUE RISK TOLERANCE')
plt.ylabel('Frequency')
plt.title('Distribution of TRUE RISK TOLERANCE')
plt.show()


# Define the ranges and labels
ranges = [(0, 6), (7, 15), (16, 35), (36, 74), (75, 100)]
labels = ['Very Low Risk', 'Low Risk', 'Moderate Risk', 'High Risk', 'Very High Risk']

# Add the 'RISK TOLERANCE SCORE' column
risk_tol_model['RISK TOLERANCE SCORE'] = pd.cut(risk_tol_model['TRUE RISK TOLERANCE'], bins=[r[0] for r in ranges] + [ranges[-1][1]], labels=labels)

# Display the updated DataFrame with risk profiles
#print(risk_tol_model[['TRUE RISK TOLERANCE', 'RISK TOLERANCE SCORE']])


risk_tol_model.head()


# Count the number of data points for each risk tolerance score
risk_tol_model['RISK TOLERANCE SCORE'].value_counts()
risk_tol_model


from sklearn.ensemble import RandomForestClassifier
#Prepare the data
X = risk_tol_model[['AGE', 'KIDS', 'NET WORTH', 'INCOME', 'MARRIAGE']]
y = risk_tol_model['RISK TOLERANCE SCORE']

#Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

#Create and train the Random Forest Classifier model
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)

model_name = 'Random Forest Classifier'

#Make predictions on the test set
y_pred = rf_classifier.predict(X_test)
y_train.value_counts()

#Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

#Print value counts for y_train
print("y_train value counts:")
print(y_train.value_counts())

#Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

#Print confusion matrix
cm = confusion_matrix(y_test, y_pred)
cm_df = pd.DataFrame(cm, columns=rf_classifier.classes_, index=rf_classifier.classes_)
print("Confusion Matrix:")
print(cm_df)



# Get unique values and their counts from y_train
unique_values, counts = np.unique(y_train, return_counts=True)

# Create a DataFrame to display the counts
y_train_value_counts = pd.DataFrame({'RISK TOLERANCE SCORE': unique_values, 'Count': counts})
print("y_train value counts:")
print(y_train_value_counts)


# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, cmap="Blues", fmt="d", xticklabels=rf_classifier.classes_, yticklabels=rf_classifier.classes_)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()


#Training model with RandomOverSampler 
from imblearn.over_sampling import RandomOverSampler

# Instantiate a RandomOversampler instance
random_oversampler = RandomOverSampler(random_state=42)

#Perform oversampling with RandomOverSampler
X_oversampled, y_oversampled = random_oversampler.fit_resample(X_train, y_train)
y_oversampled.value_counts()

#Create and train the Random Forest Classifier model
rf_classifier_oversampled = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier_oversampled.fit(X_oversampled, y_oversampled)

# Assign a name to the model
model_name = 'Random Oversampler RFC'

#Make predictions on the test set
y_pred = rf_classifier_oversampled.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Print confusion matrix
cm_ros = confusion_matrix(y_test, y_pred)
cm_ros_df = pd.DataFrame(cm_ros, columns=rf_classifier_oversampled.classes_, index=rf_classifier_oversampled.classes_)
print("Confusion Matrix:")
print(cm_ros_df)


# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm_ros, annot=True, cmap="Blues", fmt="d", xticklabels=rf_classifier_oversampled.classes_, yticklabels=rf_classifier_oversampled.classes_)
plt.title("Confusion Matrix Oversampled RF model")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()


#Training model with SVC
from sklearn.svm import SVC

# Utilizing the balanced dataset from the random oversampler model  (X_oversampled and y_oversampled are the oversampled data)

#Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_oversampled, y_oversampled, random_state=42)

# Step 3: Create and train the SVM model
svm_classifier = SVC(random_state=42)
svm_classifier.fit(X_train, y_train)

# Step 4: Make predictions on the test set
y_pred_svm = svm_classifier.predict(X_test)
y_train.value_counts()

#Evaluate the model
accuracy_svm = accuracy_score(y_test, y_pred_svm)
print("Accuracy:", accuracy_svm)

#Print value counts for y_train
print("y_train value counts:")
print(y_train.value_counts())

#Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred_svm))

# Print confusion matrix
cm_svm = confusion_matrix(y_test, y_pred_svm)
cm_svm_df = pd.DataFrame(cm_svm, columns=svm_classifier.classes_, index=svm_classifier.classes_)
print("Confusion Matrix:")
print(cm_svm_df)


# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm_svm, annot=True, cmap="Blues", fmt="d", xticklabels=svm_classifier.classes_, yticklabels=svm_classifier.classes_)
plt.title("Confusion Matrix (SVM)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()


from sklearn.tree import DecisionTreeClassifier

#USING ORIGINAL DATASET IMBALANCED

#Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

#Create and train the Decision Tree Classifier model
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)

#Make predictions on the test set
y_pred_dt = dt_classifier.predict(X_test)

#Evaluate the model
accuracy_dt = accuracy_score(y_test, y_pred_dt)
print("Accuracy:", accuracy_dt)

#Print value counts for y_train
print("y_train value counts:")
print(y_train.value_counts())

#Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred_dt))

#Print confusion matrix
cm_dt = confusion_matrix(y_test, y_pred_dt)
cm_dt_df = pd.DataFrame(cm_dt, columns=dt_classifier.classes_, index=dt_classifier.classes_)
print("Confusion Matrix:")
print(cm_dt_df)

#Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm_dt, annot=True, cmap="Blues", fmt="d", xticklabels=dt_classifier.classes_, yticklabels=dt_classifier.classes_)
plt.title("Confusion Matrix (Decision Tree)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()


#TRAINING MODEL WITH DECISION TREE AND OVERSAMPLED DATA SET 

#(X_oversampled and y_oversampled are the balanced data from the random oversampler)

#Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_oversampled, y_oversampled, random_state=42)

#Create and train the Decision Tree Classifier model
dt_classifier_oversampled = DecisionTreeClassifier(random_state=42)
dt_classifier_oversampled.fit(X_train, y_train)

# Assign a name to the model
model_name = 'Decision Tree Classifier'

#Make predictions on the test set
y_pred = dt_classifier_oversampled.predict(X_test)

#Evaluate the model
accuracy_dt_oversampled = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy_dt_oversampled)

# Print value counts for y_train
print("y_train value counts:")
print(y_train.value_counts())

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Print confusion matrix
cm_dt_oversampled = confusion_matrix(y_test, y_pred)
cm_dt_oversampled_df = pd.DataFrame(cm_dt_oversampled, columns=dt_classifier_oversampled.classes_, index=dt_classifier_oversampled.classes_)
print("Confusion Matrix:")
print(cm_dt_oversampled_df)

# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm_dt_oversampled, annot=True, cmap="Blues", fmt="d", xticklabels=dt_classifier_oversampled.classes_, yticklabels=dt_classifier_oversampled.classes_)
plt.title("Confusion Matrix (Decision Tree - Oversampled)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()


#Training model with GradientBoosting Classifier

from sklearn.ensemble import GradientBoostingClassifier

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

#Create and train the Gradient Boosting Classifier model
gb_classifier = GradientBoostingClassifier(random_state=42)
gb_classifier.fit(X_train, y_train)

#Make predictions on the test set
y_pred_gb = gb_classifier.predict(X_test)

#Evaluate the model
accuracy_gb = accuracy_score(y_test, y_pred_gb)
print("Accuracy:", accuracy_gb)

#Print value counts for y_train
print("y_train value counts:")
print(y_train.value_counts())

#Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred_gb))

# Print confusion matrix
cm_gb = confusion_matrix(y_test, y_pred_gb)
cm_gb_df = pd.DataFrame(cm_gb, columns=gb_classifier.classes_, index=gb_classifier.classes_)
print("Confusion Matrix:")
print(cm_gb_df)

# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm_gb, annot=True, cmap="Blues", fmt="d", xticklabels=gb_classifier.classes_, yticklabels=gb_classifier.classes_)
plt.title("Confusion Matrix (Gradient Boosting)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()


from sklearn.ensemble import GradientBoostingClassifier

#TRAINING MODEL WITH DECISION TREE AND OVERSAMPLED DATA SET 

#Prepare the data (X_oversampled and y_oversampled are the balanced data from the random oversampler)

#Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_oversampled, y_oversampled, random_state=42)

#Create and train the Gradient Boosting Classifier model
gb_classifier_oversampled = GradientBoostingClassifier(random_state=42)
gb_classifier_oversampled.fit(X_train, y_train)

# Assign a name to the model
model_name = 'Gradient Boosting Classifier'

#Make predictions on the test set
y_pred = gb_classifier_oversampled.predict(X_test)

#Evaluate the model
accuracy_gb_oversampled = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy_gb_oversampled)

#Print value counts for y_train
print("y_train value counts:")
print(y_train.value_counts())

#Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

#Print confusion matrix
cm_gb_oversampled = confusion_matrix(y_test, y_pred)
cm_gb_oversampled_df = pd.DataFrame(cm_gb_oversampled, columns=gb_classifier_oversampled.classes_, index=gb_classifier_oversampled.classes_)
print("Confusion Matrix:")
print(cm_gb_oversampled_df)

#Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm_gb_oversampled, annot=True, cmap="Blues", fmt="d", xticklabels=gb_classifier_oversampled.classes_, yticklabels=gb_classifier_oversampled.classes_)
plt.title("Confusion Matrix (Gradient Boosting - Oversampled)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show


from keras.models import Sequential
from keras.layers import Dense
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Define your data and labels
X = risk_tol_model[['AGE', 'KIDS', 'NET WORTH', 'INCOME', 'MARRIAGE']]
y = risk_tol_model['RISK TOLERANCE SCORE']

# Encode the labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
num_classes = len(label_encoder.classes_)

# Convert the encoded labels to one-hot encoded format
y_categorical = tf.keras.utils.to_categorical(y_encoded, num_classes=num_classes)

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, random_state=42)

# Define the model architecture
model = Sequential()
model.add(Dense(32, activation='relu', input_shape=(5,)))
model.add(Dense(num_classes, activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Print the model summary
model.summary()

# Train the model
history = model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)

# Make predictions on the test set
y_pred = np.argmax(model.predict(X_test), axis=1)

# Convert the encoded labels back to the original categories
y_test_original = label_encoder.inverse_transform(np.argmax(y_test, axis=1))
y_pred_original = label_encoder.inverse_transform(y_pred)

print("Classification Report:")
print(classification_report(y_test_original, y_pred_original))

# Compute confusion matrix
confusion_mat = confusion_matrix(y_test_original, y_pred_original)
confusion_df = pd.DataFrame(confusion_mat, index=label_encoder.classes_, columns=label_encoder.classes_)

# Print confusion matrix as a DataFrame
print("Confusion Matrix:")
print(confusion_df)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_df, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix Deep Learning - imbalanced dataset")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()


from imblearn.over_sampling import RandomOverSampler

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, random_state=42)

# Apply oversampling to balance the classes
oversampler = RandomOverSampler(random_state=42)
X_train_balanced, y_train_balanced = oversampler.fit_resample(X_train, y_train)

# Define the model architecture
model = Sequential()
model.add(Dense(32, activation='relu', input_shape=(5,)))
model.add(Dense(num_classes, activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Print the model summary
model.summary()

# Train the model with the oversampled data
history = model.fit(X_train_balanced, y_train_balanced, epochs=10, batch_size=32, verbose=1)

# Make predictions on the test set
y_pred = np.argmax(model.predict(X_test), axis=1)

# Convert the encoded labels back to the original categories
y_test_original = label_encoder.inverse_transform(np.argmax(y_test, axis=1))
y_pred_original = label_encoder.inverse_transform(y_pred)

print("Classification Report:")
print(classification_report(y_test_original, y_pred_original))

# Compute confusion matrix
confusion_mat = confusion_matrix(y_test_original, y_pred_original)
confusion_df = pd.DataFrame(confusion_mat, index=label_encoder.classes_, columns=label_encoder.classes_)

# Print confusion matrix as a DataFrame
print("Confusion Matrix:")
print(confusion_df)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_df, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix Deep Learning with oversampled dataset")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()


model_name = 'Random Forest Classifier'
def generate_classification_report(y_true, y_pred, model_name):
    report = classification_report(y_true, y_pred)
    print(f"Classification Report for {model_name}:")
    print(report)

def generate_confusion_matrix(y_true, y_pred, model_name):
    matrix = confusion_matrix(y_true, y_pred)
    print(f"Confusion Matrix for {model_name}:")
    print(matrix)

def generate_model_evaluation(y_true, y_pred, model_name):
    accuracy = accuracy_score(y_true, y_pred)
    print(f"Model Evaluation for {model_name}:")
    print(f"Accuracy: {accuracy}")


# Call the functions for Random Forest Classifier

generate_classification_report(y_test, y_pred, model_name)
generate_confusion_matrix(y_test, y_pred, model_name)
generate_model_evaluation(y_test, y_pred, model_name)


model_name = 'Random Oversampler RFC'

def generate_classification_report(y_test, y_pred, model_name):
    report = classification_report(y_test, y_pred)
    print(f"Classification Report for {model_name}:")
    print(report)

def generate_confusion_matrix(y_test, y_pred, model_name, classes):
    matrix = confusion_matrix(y_test, y_pred)
    cm_df = pd.DataFrame(matrix, columns=classes, index=classes)
    print(f"Confusion Matrix for {model_name}:")
    print(cm_df)

def generate_model_evaluation(y_test, y_pred, model_name):
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Model Evaluation for {model_name}:")
    print(f"Accuracy: {accuracy}")


# Call the functions for Random Oversampler RFC
generate_classification_report(y_test, y_pred, model_name)
generate_confusion_matrix(y_test, y_pred, model_name, rf_classifier_oversampled.classes_)
generate_model_evaluation(y_test, y_pred, model_name)


model_name = 'Decision Tree Classifier'

def generate_classification_report(y_true, y_pred, model_name):
    report = classification_report(y_true, y_pred)
    print(f"Classification Report for {model_name}:")
    print(report)

def generate_confusion_matrix(y_true, y_pred, model_name, classes):
    matrix = confusion_matrix(y_true, y_pred)
    cm_df = pd.DataFrame(matrix, columns=classes, index=classes)
    print(f"Confusion Matrix for {model_name}:")
    print(cm_df)

def generate_model_evaluation(y_true, y_pred, model_name):
    accuracy = accuracy_score(y_true, y_pred)
    print(f"Model Evaluation for {model_name}:")
    print(f"Accuracy: {accuracy}")



# Call the functions for Decision Tree Classifier
generate_classification_report(y_test, y_pred, model_name)
generate_confusion_matrix(y_test, y_pred, model_name, dt_classifier_oversampled.classes_)
generate_model_evaluation(y_test, y_pred, model_name)


model_name = 'Gradient Boosting Classifier'

def generate_classification_report(y_true, y_pred, model_name):
    report = classification_report(y_true, y_pred)
    print(f"Classification Report for {model_name}:")
    print(report)

def generate_confusion_matrix(y_true, y_pred, model_name, classes):
    matrix = confusion_matrix(y_true, y_pred)
    cm_df = pd.DataFrame(matrix, columns=classes, index=classes)
    print(f"Confusion Matrix for {model_name}:")
    print(cm_df)

def generate_model_evaluation(y_true, y_pred, model_name):
    accuracy = accuracy_score(y_true, y_pred)
    print(f"Model Evaluation for {model_name}:")
    print(f"Accuracy: {accuracy}")


# Call the functions for the Gradient Boosting Classifier
generate_classification_report(y_test, y_pred, model_name)
generate_confusion_matrix(y_test, y_pred, model_name, gb_classifier_oversampled.classes_)
generate_model_evaluation(y_test, y_pred, model_name)



